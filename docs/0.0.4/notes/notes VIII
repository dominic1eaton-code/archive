The Corporation (2003) notes:
- the nature of "the institution", subsidiary
- the organization / firm / corporation as a "person" / agent / entity
- privacy generated wealth (the "private" entity / agent, the effects / need of privacy) ? privitization ?
- the effects and need for ownership
- consummate ownership (of everything)
- the rise / need of ownership
- maintain (objects, entities, resources, etc...) in "the commons" / remain under "common[s] control"
- the "social role" and the abstract notion of "role"
- market share optimization
- the "widget" (a generalization of "resource")
- on consent
- signs / metrics for progress... ?
- monopolies, firms, coalitions (and economic agents) ... ?
- game theoretic agents (players) ... ? a [serious] game (complex autonomous economic system) ?
- arbitration agents
- tort law and the blockchain 
- a [serious, complex] game - complex [autonomous] economic systems
- the rise and nature of the "audit" and the "self-audit" (on the nature of self-auditing)

subsidiary

a peculiairty exists here as it may be observed that a complex system is in fact a constituent part of another, larger complex system, yet the complexity of complex sub-system may not be apparent, and it may eveen be the case the complex sub-system as a system that follows very simple (and local) rules (a flock of birds, where from the biological perspective, each bird may possess significant (biological) complexity (complex branching structures, complex mocules, complex energy management mechanisms, etc...), yet the overall behavior of the birds may be rather simple and they may follow simple rules to produce emergent behavior (flocking)) (similar analogy with humans).  the preconsious principles (complexity is "hidden" (or reduced) fromt the agent possessing it) and the complexity encapsulation principle (complexity is "hidden" (or reducing) accross varying [complexity] scales)



set I
- the generality (and converse / dual specialty) principle (principles of "equality" vs "special treatment")
- the generalist (and converse / dual specialist) principle (principles of generalism and specialism)
https://www.d.umn.edu/~gshute/softeng/principles.html
- the linearity principle (incremental developments)
- the consistency principle
- the anticipation (and predictive / prediction) principle
- the "general" (and the "specialist")

- Godel coding

Animal Grouping
- zones + artificial potential fields + steering behaviors + agent [rigid] formation algebra + misc. (emergent behavior, complexity, [distributed] control mechanisms) ?
- agents either place "APF points" in the environent, or just react to already placed APF points ?
- APF points (local, global objective realization) placed in relative referene frames (changes of reference frames ?) ?

- reductionism as understanding the part form together a larger whole, holism as an understanding that a whole can not simply be viewed by its constituent parts, and generalism as to understand that both reductionsism and holism are both necessary for a general understanding of a given system (or notion) in question (and specialism is to understand that there is an "one or the other choice" between (or among) a[ny] give school of thought).


Side Conclusion
The two "singularity" points of minimal and maximal entropy may be such that a given [closed] system may tend toward maximal entropy (and therefore, "true" uniformity [a breaking down into the most basic / fundamental components]), but there are moments / points of "inflections" or "sparks" where the "just right conditions" (and interactions) allow for components to form together to become increasingly complex. These "spark" points could lead to the creation of an entity (abstractly denoted as "life") for which continuously tends toward a "minimization of entropy". The idea of the universe tending toward a maximization of entropy may be such that the universe is, in reality, tending toward a [state of] "natural equilibrium" (of pure, and fundamental uniformity (and perhaps homogeneity as well), and of minimal complexity), and that the entity of "life" has an opposite agenda in that it tends toward maximal complexity and minimal entropy (with all of the "noise" and variability in between these two "natural equilibrious" states (trajectories, paths, processes, mechanisms)). Under and following these ideas, it may be of interest to understand what it would mean to have control mechanisms (which require energy [work, temperature (3rd law of Thermodynamics)] as according to the second law of thermodynamics) that, similarly, abide by these principles (as well as ponder what it would mean to be in a given state between the two extremes described). Naturally, may one ask the question of why or how would an entity come to be, as to minimize its number of states and challenge the second law of thermodynamics (a perhaps "reductionist" question) ? From the point of view of the generalist, however, might the question of the starting state, the ending state, and the path states in between may be framed in an alternative manner. The "intrinsic noise" that is natural to any complex [chaotic, emergent] system may be such as to suggest that the characterization of any singular point (or path, trajectory) is not of the most effective means to understand (or describe) mechanisms for control. This is not to suggest that control of dynamical systems is not possible, but to note that the meaning of "controllability" in complex systems may be more "non-traditional" in nature, and even the "standard scientific process" might seek itself a reformulation as it deals with complex [autonomous] systems. From all that has been suggested so far, it seems clear that some "entropy-based" control mechanism is necessary for the [complex] control of complex systems (perhaps in the form of some evolutionary, or "fractilic", or emergent [behavioral] mechanism), and when one begins to connect the ideas presented previously with those surrounding machine learning (hierarchical reinforcement learning for example) where these "learning" models serve as "data (or complexity) interpolators", one may begin to see that certain, consistent (and perhaps symmetric) phenomena begin to appear which may further give explication as to the exact nature of what a given "entropy-based controller" (or "entropy-controller") may actually be and what it should do to achieve some given objective (find some "ideal" (stable) state). What may be the case is that linearity is perhaps always a possibility (within a certain bound of course) (given enough "resources" [time, space, money, widget, etc…]), but the efficiencies and utility of developing such linear systems are significantly degraded by the constraints necessary to have the linear system exist (and be maintained / self-maintaining), and the non-linear (complex, interpolating) system is thought to provide a better method as to solve problems of [non-trivial] increasing difficulty.

After a bit of self-reflection, may one also begin to question the nature (or reason) of using entropy in the first place as the fundamental unit (variable, structure) for design and control of complex systems (it could very well be that some of other fundamental unit could exist that gets the job done just as well (or"better") (Pareto optimal solutions…)), but generally is there the idea that there exists some such "fundamental variables" (baseline) of design, control, and characterization of [any given] complex system[s]. Furthermore these "fundamental variables" (at least in their abstract form[s]) are thought to be "reference [or observation] frame free" (perhaps implying tensorial representations…), and are more so relative terms (for which it is believed that any complex autonomous system shall abide by the principles of understanding that all things are more so relative to one another, and that absolutes are a more "idealic" [but not always, or necessarily existing] concept).

What is thought to be an important result from the previous conclusion is that there is now sought to be the finding of "correspondence (or consistency) principles" between "classical" [linear, reductive, pure theoritic (ideal), fully characterizable] systems and complex [emergent, chaotic, generalist, interpolative] systems, where these principles (and all principles ideally) can be written as invariances (symmetries) in terms of some given set of fundamental variables [structures] (entropy, energy, spacetime, gravity, scale, complexity, modality, etc...). This would also imply the need for a solid theoretical foundation for complex systems as well, and even more broadly, some sort of unified theory between "classical" and [general ("complex systems" here refers to such system in their most general, abstract form [concretely these could be anything (biological, complex machines / networks, economies, etc...)])] complex sytems (written in terms of common [fundamental] variables [structures]). Given a firm theoretical foundation and solid frameworks and descriptions of this more unified perspective of systems, shall it perhaps be abundantly more clear as to what applications are possible with such a [more] complete systems theory, and shall the nature of these "entropy-based control mechanisms" also be given more clarity. Proper (and commonalities in) representation is also a natural key ingredient of consideration. The formation of a systems theory in a continuum between "classical" and complex systems seems to be a next reasonable step forward (from given, current knowledge and understandings) where these "classical" systems represent a more simplisitc, yet fully "explainable" behaviors / states (that also scale linearly with complexity), and complex systems are more representative of somewhat more "black-box", or emergent behaviors / states (that hide or reduce increasing complexity) (also, may one note that behaviors, and states are part of the "five modalities" mentioned in previous works, and these modalities are thought to be part of the commonality representation theory of the general systems theory). Given applications from theory and frameworks, does one now come into the field of "complex systems engineering" (or also "general systems engineering", I suppose, as well), where the study of metrics, performance, controllability, etc..., of such systems becomes relevant (and furthermore, can these "general/complex systems engieering" be further sub-divided into various "flavors" [complex biological systems development, complex chemical, economic, etc...]). This seems to be a natural progession (at least for now).

Taking another step back, may one begin to question the utility of "complex systems engineering" (and complex systems theory) and may one seek to understand the applications and implications of studying this [emerging and "emergent"] field. Has it been suggested in previous works that "complex systems engineering" is thought to likely take on many sub-fields or "specializations" (or "flavors"), where each one of these sub-components are linked by the common, unifying thread (theory) (of complex system theory…), and even complex autonomous systems [theory and engineering], is but a sub-field of the larger, encompassing field. Why is this field here (is there even a "field" ?) ? what can one do with this field ? what would study of this field mean ? these questions are some of the principle questions that this work (in its entirety) hopes to answer (and there are of course many other questions as well).



- this cyclic (reversible, irreversible process; fourier, harmonics, etc ... ?) activity where systems form together to a given level of complexity, to reach a point to where they "simplify" (or "unify", the creation / rise of "pre-consciousnesses") and proceed to become part of a larger system, which in terms continues to build into a system of increasing complexity. A seemingly "fractilic" pattern may be seen to arise, as perhaps some simple building block (or shape, structure) begins to replicate and form into an increasingly complex structure, yet eventually does it reach a point of "regenerating" the original simple structure (the "re-simplification") (also this "regeneration" of the original structure may not obviously be such as according (respect) to form / morphology of the original object [the regenerated object may "look" different (externally) but may perhaps be the same intrinsically]), where the newly generated structure then proceeds to become part of a new system of increasing structural complexity, throughout all varying degrees of scale. This interesting "fractal principle" may perhaps be written in terms of the fundamental variables (the complexity scale variable perhaps), and might yet demonstrate
